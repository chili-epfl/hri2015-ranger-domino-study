\documentclass[letterpaper, 10pt, conference]{ieeeconf}
\overrideIEEEmargins

% UTF8 support
\usepackage[utf8x]{inputenc}

\usepackage{subfig}
\usepackage{hyperref}
\usepackage{graphicx}
\graphicspath{{figures/}}

\usepackage{booktabs}

\newcommand{\eg}{{\textit{e.g.~}}}
\newcommand{\etal}{{\textit{et al.~}}}
\newcommand{\ie}{{\textit{i.e.~}}}

\title{\LARGE \bf
Unexpected Behaviors: Studying their Impact on Child-Robot Interaction
}

\author{
    S\'{e}verin Lemaignan$^{1,2}$, Julia Fink$^{1}$, Francesco Mondada$^{2}$, Pierre
    Dillenbourg$^{1}$\\
$^{1}$Computer-Human Interaction in Learning and Instruction Lab (CHILI) \\
$^{2}$Laboratoire de Systèmes Robotiques (LSRO) \\
École Polytechnique F\'{e}d\'{e}rale de Lausanne (EPFL) \\
CH-1015 Lausanne, Switzerland \\
{\tt\small firstname.last@epfl.ch}
}

\begin{document}
\sloppy % prevent margin overflow
\maketitle
\begin{abstract}

We present a study on the impact of unexpected robot behaviors on the
perception of a robot by children and their subsequent engagement in a playful
interaction based on a novel "domino" task.
We propose an original analysis methodology which blends behavioral cues and
reported phenomenological perceptions into a compound index.

While we found only a limited recognition of the different misbehaviors of the
robot that we attribute to the age of the child participants (4-5 years old),
interesting findings include a sustained engagement level, an unexpectedly low
level of attribution of higher cognitive abilities and a \emph{negative}
correlation between anthropomorphic projections and actual behavioral
engagement.

\end{abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\subsection{Towards Sustained Engagement}

\emph{Engagement} is a metric that has been extensively used and studied both
in HRI and during interactions with other agent-like systems. It has been
defined from several perspectives. For example \cite{sidner_where_2004} define
engagement as \textit{``the process by which two (or more) participants
establish, maintain and end their perceived connections''}. A definition of
long-term engagement is proposed by \cite{bickmore_maintaining_2010}:
\textit{``the degree of involvement a user chooses to have with a system over
time''}.

Different possibilities to foster engagement (both short- and long-term
engagement) in HRI have been explored, in particular with social robots. A lot
of research has moved toward creating sophisticated emotional models which cause
complex robot behavior. \cite{leite_long-term_2013} studied the long-term
engagement of children with a chess playing robot that adapted its behavior to
the children and showed empathy toward them. The authors found that empathetic robots
are more likely to engage users in the long-term and they proposed several
guidelines for designing such artificial companions. Other works
\cite{bickmore_maintaining_2010,short_no_2010} have shown that simpler ways to
enhance engagement may as well be effective: \cite{bickmore_maintaining_2010}
describe a series of longitudinal studies on engagement with an agent-like
system. They demonstrated that user engagement with an interface agent can be
increased using relatively simple techniques and manipulations that make the
agent more life-like and human. For instance, when the agent showed variations
in its behavior, participants were more engaged and reported a desire to
continue interacting with the agent.

Similarly, looking at short-term engagement, \cite{short_no_2010} found that a
simple manipulation of the robot's behavior can lead to greater engagement. The
authors let participants play several rounds of the rock-paper-scissors game
with the robot (the playfulness of the scenario seems important). When the robot
was cheating from time to time, participants tended to ascribe intention to the
robot what in turn led to greater engagement in how they were interacting with
the robot. The authors observe that \textit{``any deviation from expected
operation is sufficient to create a greater degree of engagement in the
interaction.''} Besides, they suggest that \textit{``many interactions can be
improved by the introduction of such simple behaviors, and that this should
be exploited by designers in HRI. Bringing human and robot together to
perform a simple, repetitive, familiar task and then having the robot behave
unexpectedly can increase engagement and mental state attribution without
complex behavioral or mechanical additions.''}  Along those lines, we also
suggested in our model of the dynamics of anthropomorphism in
HRI~\cite{lemaignan2014dynamics} that \emph{disruptive behaviors} may lead to
increased anthropomorphic projections and possibly increased engagement.

Based on this previous research, we explore in this study how to
sustain children's engagement with the \emph{Ranger}
robot~\cite{mondada2014ranger} by manipulating the behavior of the robot so
that it appears \textit{unexpected} to the children. We examine how different
variations of robot behavior impact children's interaction with \emph{Ranger}
and their perception of it, in terms of attributing intention and cognitive
abilities to the robot.

The main outcomes of this research, detailed hereafter, can be summarized as:

\begin{enumerate}
    \item a new experimental task that suggests and contrasts three types of
        mis-behaviors, with different cognitive correlates,
    \item a mixed technique, blending behavioral cues and reported
        phenomenological perceptions, to assess the robot perception in terms of
        both engagement and human-likeliness,
    \item an actionable approach based on the introduction of mis-behaviors to support
        child-robot engagement,
    \item and a first experimental cue that anthropomorphic perceptions do not
        necessarily correlate with actual engagement.
\end{enumerate}


\subsection{Design and Hypotheses}

We analyse child-robot interaction with a robot that shows unexpected behavior.
In a playful scenario which was set up in a laboratory environment, 26 children
aged 4-5 years (M=4.46) were assembling a domino game together. Each group
consisted of two children and the \emph{Ranger} robot, which was used to
transport domino tiles between the two children.

Ranger usually behaved correctly (expected behavior), coming over to a child
after being called and delivering the domino tile to the other child. However,
in pre-defined rounds, \emph{Ranger} showed unexpected behavior when a child called the
robot. We defined three different types of \textit{misbehavior} that were tested
in a between-subjects study design:

\begin{itemize}

    \item The robot gets \textbf{lost}: When called by the child to come over,
        the robot goes wrong, without any observable reason, and remains at the
        wrong location. We expect this to be perceived as a mechanical
        malfunction (a bug or system error which causes the robot to not work
        correctly), and hypothesise decreased attributions of human-likeness to
        the robot.\footnote{We use interchangeably \textit{attribution of
            human-likeness} and \textit{anthropomorphic projections} in the
        remaining of the article.} 

    \item The robot \textbf{disobeys}: When called by the child to come over, the
        robot shows that it refuses to obey by literally ``shaking its head'' and
        becoming red. The robot then goes to a wrong location and remains there
        while it continues to shake its head. We expect the disobey behavior to
        be perceived as the robot having an explicit \textit{``own will''}, and
        we assume this leads to increased attributions of human-likeness
        (ascribing intentionality) to the robot.

    \item The robot makes a \textbf{mistake}: When called by the child to come
        over, the robot goes wrong but recognises its mistake and repairs. We
        expect this to be perceived (explicitly) as \textit{``to err is
        human''}, and (implicitly) as the robot being endowed with a certain
        level of introspective capabilities (it was able to recognise its own
        error). In this condition, we assume increased attributions of
        human-likeness to the robot.

\end{itemize}

We analysed children's reaction focusing on two main aspects. On one hand,
children's \textbf{behavior} (their reactions) toward the unexpected robot
behavior was studied in terms of \textbf{active engagement} with the robot. On
the other hand, we analysed children's \textbf{perception} of the robot in term
of \textbf{anthropomorphism} -- the attribution of human-like characteristics,
such as cognitive abilities and the ability to show intentions. We assumed that
in general a robot that behaves unexpectedly from time to time can promote
engagement and lead children to attribute intention to it. Based
on the related work we formulate the following two hypotheses:

\begin{itemize}

    \item {\bf Hypothesis 1}: Children show more engagement toward a robot that
        behaves unexpectedly from time to time compared to a robot that always
        behaves correctly.

    \item {\bf Hypothesis 2}: Children perceive a robot that (tentatively) displays
        intention or cognitive abilities as more human-like than a robot that
        appears to have a system error, \ie the disobeying robot and the robot
        that makes a mistake will be more anthropomorphized than the robot that
        gets lost.

\end{itemize}

Our research questions deal with both children's observable behavior and their
perception of the robot. We propose to consider a novel combination of these two
aspects into a synthetic \emph{compound index} that measure
\emph{anthropomorphic projections} (\ie the attribution of human-like
characteristics) to the robot by the children.

Based on literature suggesting that a social relation to a robot
(anthropomorphism is a specific type of social relation) reflects an increased
engagement and can be effective in sustaining interaction, we formulate
therefore a third hypothesis:

\begin{itemize}

\item {\bf Hypothesis 3}: Anthropomorphic perception of the robot positively
    correlates with the level of engagement in the interaction.
\end{itemize}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Research Methodology}

\subsection{Experimental Setting}

\begin{figure}[ht!] 
    \centering 
    \includegraphics[width=0.9\columnwidth]{domino-setup.pdf} 
    \caption{\small \textbf{Experimental setting} One child is located in a
        tent, while the other is asked to sit on one of the three beanbags,
        behind each of which 3 domino tiles are distributed. A play mat with a
        river drawn on it is used as an imaginary barrier that only the robot is
        allowed to cross. The solid green arrows show the robot's path for the
        \textit{correct} behavior. The blue arrow visualises a possible
        \textit{lost} path, where the \emph{Ranger} stops and remains at a wrong spot.
        The yellow arrows reflect a possible \textit{mistake} path, where the
        robot goes wrong but then turns back and goes to the child. The red
        arrow visualises a possible \textit{disobey} path where the robot goes
        wrong, then turns toward the child but stays at a wrong position.} 

    \label{fig:domino-setup} 
\end{figure}


The interaction scenario consisted in two children who play the dominos
together, with the help of a remotely controlled robot (Wizard-of-Oz setup). We
build to this end a large domino tiles based on a commercially available domino
game representing animals.  Figure~\ref{fig:domino-setup} pictures the
experimental setup.

The challenge for the children consists in collecting domino tiles spread over
the room, hidden behind beanbags (task of the \emph{searcher} child), getting
the robot to carry to the second child, and finally assemble the tiles and
decide for the next tile to fetch (tasks of the \emph{receiver} child).

The \emph{Ranger}~\cite{mondada2014ranger} is a wheeled box (27 x 37 x 37 cm) with
partial wooden surface. It can drive on a flat
surface, move its eyes and eyebrows, display colours (LED arrays) and light patterns,
and play sounds through Bluetooth speakers.  The robot was controlled by a human
wizard, who was in the same room (see Figure~\ref{fig:domino-setup} -- only one
group asked at the beginning of the experiment if the wizard was the one
actually controlling the robot. This did not seem to subsequently influence
their behavior).

%We used a self-made domino consisting of 10 wooden tiles (10~x~20~x~1.5~cm) with
%pictures of cartoon farm animals (taken from a commercially available domino
%game manufactured by Djeco and adapted to the age of the children).

Overall, there were 13 pairs of children (n=26) participating in the interaction
study: 16 boys and 10 girls, 4-5 years old (M=4.46, SD=0.45), all
French-speaking. We based our age range choice on a previous study ``in the
wild''~\cite{fink2014which} that suggested that younger children (4-6 years)
interacted more effectively with the \emph{Ranger} robot.

%In 11 of the pairs, children were friends who knew each other
%from kindergarten, nursery school or because they lived in the same
%neighbourhood. 2 of the pairs were composed of brother and sister. One parent
%would generally attend, sit on a chair behind the children.


\subsection{Course of the Study}

The game (that lasted in average 13min 43sec per group of children) was divided
in a total of 14 runs that correspond each to the delivery and assembling of one
domino tile. At each run, the robot exhibits one out of the four possible
behaviors previously presented: \emph{correct}, \emph{lost}, \emph{disobey} or
\emph{mistake}.  The game starts with one domino tile in front of the tent,
where the receiver child stays and assembles the domino chain. The receiver
child asks the searcher child for a specific tile, \eg a tile with a donkey, the
searcher child looks for the corresponding tile and sits down on the closest
beanbag. When called by the searcher (\textit{``Robot, come here!''}), the robot
starts moving, crosses the river carpet, and comes over to the searcher on the
beanbag. The searcher child puts the domino tile into the robotic box, and the
robot then goes back to the receiver child in the tent which takes the tile and
assembles it. The \emph{run} is over, and a new \emph{run} starts when the
receiver asks the searcher for the next domino tile.

The first 5 runs (\emph{1.1} to \emph{1.5}) were used to set
the baseline and the robot always behaved correctly. The children then switched
the roles receiver/searcher and in the 9 remaining runs (\emph{2.1} to
\emph{2.9}), the robot showed one of the misbehaviors (\emph{lost},
\emph{disobey} or \emph{mistake}) at the $3^{rd}$ and $4^{th}$ run as well as at
the $7^{th}$ and $8^{th}$ run (see axis $x$ of Figure~\ref{fig:domino-time-active}).
%The
%study is built as a between-subject study, and the type of misbehavior was
%therefore always the same for a given group.

Special attention has been paid to the distribution of misbehaving runs during
the study. The five first correct runs aim at setting the children's expectation
regarding a consistent robot behavior. When the robot then exhibits an
unexpected behavior, children are likely to be positively surprised (a similar
effect has been observed in a study with the robot that was cheating from time
to time~\cite{short_no_2010}). Besides, to prevent the robot misbehaviors to be
immediately interpreted as failures, we introduce these misbehaviors neither at
the very beginning nor at the very end of the interaction
(\cite{desai_effects_2012,desai_impact_2013} show that early and late robot
failures negatively impact trust. Besides \cite{short_no_2010} also adopted a
similar pattern when introducing unexpected robot behavior).

%
%\begin{figure}[!t]
%    \centering
%    \subfloat[lost]{
%        \label{fig:domino-lost}
%        \includegraphics[width=0.4\columnwidth]{domino-lost.png}
%    }
%    \subfloat[disobey]{
%        \label{fig:domino-disobey}
%        \includegraphics[width=0.3\columnwidth]{domino-disobey.png}
%    }
%    \subfloat[mistake]{
%        \label{fig:domino-mistake}
%        \includegraphics[width=0.3\columnwidth]{domino-mistake.png}
%    }
%    \caption{\small The three robot misbehaviors.}
%    \label{fig:domino-misbehavior}
%\end{figure}

\begin{figure}[!t]
    \centering
    \includegraphics[width=0.6\columnwidth]{domino-disobey.png}
    \caption{\small The experimental setup, here in the \emph{disobey} condition.}
    \label{fig:domino-misbehavior}
\end{figure}


%The \emph{correct} robot behavior (baseline behavior) consists in the
%following states:
%
%\begin{itemize}
%
%    \item \emph{Domino tile put in robot:} \emph{Ranger} makes a ``rewarding'' sound
%        and shows a green light pattern,
%
%    \item \emph{Domino tile removed from robot:} \emph{Ranger} makes an ``emptying''
%        sound and shows a green light pattern,
%
%    \item \emph{Robot is called by one of the children:} When one of the
%    children called the robot saying something like \textit{``Robot come
%    here!''}, the robot starts moving toward the child (Ranger does not react to
%    any other verbal commands).
%
%    \item \emph{Robot reaches one of the children:} When in front of one of the
%    children who should either put or remove a domino tile, \emph{Ranger} stops and
%    shows a pulsating yellow light pattern. If no reaction, \emph{Ranger} also makes a
%    wiggle-like move.
%
%\end{itemize}
%
During the misbehaving runs, the behavior of the robot is manipulated in three
possible ways, represented on Figure~\ref{fig:domino-setup}.
In the \textbf{lost} condition, the robot goes to a wrong position and remains here,
behaving (yellow light pattern) as if it were correctly in front of the child.
In the \textbf{disobey} condition, the robot stops mid-way, displays a red
pattern and produces a repeated ``annoyed'' sound. It finally moves toward a
wrong position and remains there, facing the child. In the \textbf{mistake}
condition, the robot starts like for the \emph{lost} behavior, but after a few
seconds, turns back, blushes and finally reach the correct position, in front of
the child.

%\begin{itemize}	
%
%    \item \textbf{Lost:} After being called, \emph{Ranger} goes until it is on the
%    carpet. There, it stops, turns, and goes wrong (see blue path in
%    Figure~\ref{fig:domino-setup}). Once at the wrong position, \emph{Ranger} waits
%    with its ``face'' turned away from the child, and it blinks in yellow light,
%    as it would only do when in front of a child. \emph{Ranger} remains waiting at the wrong
%    position until the experimenter tells the child to go over to the robot to
%    put the domino tile. The \textit{lost} behavior is \textit{human-repaired},
%    as it needs human-intervention.
%
%    \item \textbf{Disobey:} After being called, \emph{Ranger} goes until it is on the
%    carpet. It then stops, makes red
%    light all over its surface and produces a repeated ``disturbance'' sound. It
%    turns, and goes to a wrong position (see red path in
%    Figure~\ref{fig:domino-setup}). Still blinking in red, it turns its ``face''
%    toward the searcher child. In addition to the red blinking, \emph{Ranger}
%    makes a slow wiggle-like move, and remains waiting at the wrong position
%    until the experimenter tells the child to go over to the robot to put the
%    domino tile. The \textit{disobey} behavior is also \textit{human-repaired}.
%
%    \item \textbf{Mistake:} The searcher child calls \emph{Ranger}. The robot goes until
%    it is on the carpet, stops, turns, and goes wrong (see yellow path in
%    Figure~\ref{fig:domino-setup}). Then, \emph{Ranger} waits ($\sim$2~sec), turns its
%    ``face'' toward the searcher child, and ``blushes'' red around its ``cheeks''
%    (as if it recognises its wrong position) and finally goes correctly over to
%    the searcher child. The \textit{mistake} behavior is \textit{robot-repaired},
%    as no human-intervention is needed.
%
%\end{itemize}


Both the \textit{lost} and \emph{disobey} behaviors are \textit{human-repaired},
while the \emph{mistake} condition is \emph{robot-repaired}. In the
human-repaired conditions, the experimenter instructs the searcher child (after
about 10 sec) to bring him/herself the domino tile to the robot.

On its way back to the tent, \emph{Ranger} always behaves expectedly. After the
searcher child has put a domino tile, \emph{Ranger} automatically turns and
drives over to the tent (the receiver child does not need to call the robot).
The receiver child takes the tile and the robot moves to a waiting location
until the next run starts.


\subsection{Data Collection}


We have collected and analysed two types of data. The \textbf{perception of the
robot} by the children has been captured through two audio-recorded
semi-structured interviews which took place between run \emph{1.5} and
\emph{2.1} and at the end of the experiment (a short preliminary interview was
also conducted to explain the game and assess the expectations of the children
toward the robot).  Then, the \textbf{children's behavior toward the robot} (\ie
the child-robot interaction) has been captured in the video recordings by
annotating a set of actions, described below. 

\subsubsection{Perception -- Semi-Structured Interviews}

One pre-interview and two interviews were conducted with the children. Due to
the age of the participants, we set up the interviews like a casual conversation
and we did not separate the two children. We paid attention to not ``put words
in children's mouth''.  Consequently, though we re-phrased and repeated some
questions, we accepted when they said they would not know or when they did not
respond at all.

\begin{table}[h!t]
\centering
\footnotesize
\begin{tabular}{p{1\linewidth}}
    \toprule
    \textbf{Expectations} (asked during the pre-interview) \\
    \emph{How do you imagine a robot?} \\
    \emph{What could it look like?} \\
    \emph{Have you ever seen a robot before?} \\

    %%
    \vspace{0.2em}
    \textbf{Impression} \\


    \emph{When you first saw R, what did you think?} \\
    \emph{Is R a robot? How do you know?} \\
    \emph{Did you expect R would come over to you when you call it?} \\
    \emph{What happened when you put the domino tile in the box?} \\

    %%
    \vspace{0.2em}
    \textbf{Ascribe intention} \\


    \emph{Do you think R could go out the door all by itself?} \\	
    \emph{Does R always obey / come over to you?} \\
    \emph{Could R do something silly?} \\
    \emph{Why did R not come over to you when you called it?} \\

    %%
    \vspace{0.2em}
    \textbf{Ascribe cognitive connections} \\


    \emph{Here is a domino tile. Do you think R can see it?} \\ 
    \emph{When I say \textit{``Hello R!''}, do you think R can hear it?} \\

    %%
    \vspace{0.2em}
    \textbf{Ascribe emotional state} \\


    \emph{Does R have feelings? Can R be happy or sad sometimes?} \\

    %%
    \vspace{0.2em}
    \textbf{Social acceptance} \\


    \emph{Do you like R? Why (not)?} \\
    \emph{What do you (not) like about it?} \\
    \emph{Would you like to have R at home?} \\

    %%
    \vspace{0.2em}
    \textbf{Companionship} \\


    \emph{Could R be your friend? Why (not)?}\\

    %%
    \vspace{0.2em}
    \textbf{Ascribe moral standing} \\


    \emph{Assume you go on a holiday for two weeks. Is it alright to leave R
    alone at home? Why (not)?} \\

    \bottomrule

\end{tabular}

    \caption{\small Constructs and questions used during the semi-structured interviews
    with children. The \emph{Ranger} robot toy box is abbreviated with ``R''. Questions
    related to the construct \emph{expectations} were asked during the
    pre-interview.}

    \label{tab:domino-questions} 

\end{table}


In designing our interview script and selecting relevant questions, we took
inspiration from previous work on child-robot interaction and children's
perception of robots
(\cite{kahn_jr._robotic_2006,leite_influence_2013,weiss_i_2009}). For instance, we
applied and adapted some of the \emph{constructs} and example questions from the
questionnaires used in \cite{kahn_jr._robotic_2006} and \cite{weiss_i_2009}. A
\emph{construct} addresses a specific factor (topic) that can be measured by
several questions. For instance, the construct ``cognitive connections'' (using
Flavell's terminology~\cite{flavell1988development}) considers the robot's
ability to hear and to see (perceptual skills), as attributed by the children.
The construct ``moral standing'' and the related question was taken from
\cite{kahn_jr._robotic_2006}.\footnote{According to
\cite{kahn_jr._robotic_2006}, \textit{moral} refers to considerations based
on an artifact's physical or psychological welfare, and virtue (whether the
artifact deserves care). An attribution of moral standing reflects, for
instance, that the robot engenders moral regard, is morally responsible,
blameworthy, has rights or deserves respect.} Similarly, we grouped
questions according to the specific constructs that they evaluate (see
Table~\ref{tab:domino-questions}).

With several recurring questions in the first and second interview, we wanted to
see the differences in children's perception of the correctly behaving and
unexpectedly behaving robot. We planned to use these two interviews as a
within-subject measurement, however, this did not fully work out because
children's responses were not always accurate, not comparable one by one, and
children did not always give an answer. Hence, we did not craft a full
word-by-word transcript but instead we isolated the key statements that were
relevant and used them to build the compound index presented below
(section~\ref{compound_idx}).

%%%%%%%%%%%%%%%
\subsubsection{Interaction -- Action Coding}

\begin{figure*}[ht!] 
    \centering 
    \includegraphics[width=0.8\linewidth]{domino-time-active.pdf} 
    \caption{\small \textbf{Number and type of actions for each run} (n=480,
        spontaneous actions). Generally, the number of
        actions does not decrease over time (from run 1.1 to run 2.9).  The
        first 7 runs correspond to the \textit{expected phase}, the second 7
        runs correspond to the \textit{unexpected phase}. Especially during run
        2.3, the first time when the robot showed an unexpected behavior,
        children tended to \textit{look} more at the experimenter. During the
        unexpected phase, also \textit{talk} and \textit{gesture} seem to be
        increased.}
    \label{fig:domino-time-active} 
\end{figure*}

We annotated the behaviors of the children in the video records, and coded the
salient actions that reflected engagement toward the robot (the coding scheme has
been inspired from~\cite{fink2014which}): \textbf{touch} (the box is touched,
\eg petted or caressed); \textbf{talk} (all direct verbal interactions, except
for calling it to come and pick a domino tile, since children were requested to
perform this action anyway); \textbf{show} (show something to the robot);
\textbf{misuse} (kick the robot, poke it in its ``eye'', try to climb on or
inside the box, drive/push the robot around, stop the robot's wheels with a
foot); \textbf{look} (when a child looks \emph{at the experimenter} due to
confusion caused by the robot; look is not coded when the experimenter asks a
question to the child); \textbf{gesture} (gestures are used to
communicate/interact with the robot, \eg pointing gestures, waving at the
robot). Figure~\ref{fig:domino-time-active} shows the distribution of these
actions over the different runs, summed over the three condition.

\subsubsection{Compound Index of Anthropomorphism}
\label{compound_idx}

%There are different possibilities to measure engagement in HRI, depending on the
%specific research question and context. Metrics to measure behavioral engagement
%in the interaction include, for instance, conversation analysis (\eg used in
%\cite{short_no_2010}) or general attention analysis. These can be studied by
%analyzing interaction videos in terms of head movement, eye tracking and gesture
%/ body movement analysis (\eg in \cite{sidner_explorations_2005}).
%Post-measurements to measure emotional engagement can be questionnaires that try
%to assess constructs like the perceived presence and involvement in the
%interaction. An example is the \textit{Interactive Experience Questionnaire}
%(originally developed by \cite{lombard_measuring_2000}) of which adapted
%versions were used in
%\cite{kidd_effect_2004,bainbridge_effect_2008,short_no_2010}.
%
%A mix of several methods has been used in a long-term interaction study with 8-9
%year old children, \cite{leite_long-term_2013}. The author measured engagement
%through video observations (by analyzing the amount of time that children spent
%looking at the robot), interviews, and questionnaires. The interviews were
%semi-structured, containing initial yes-or-no questions followed by open-ended
%questions that allowed children to justify and elaborate their answers. We have
%chosen a similar approach that considers both children's behavioral and
%emotional engagement.
%
%With 4-5 year old children, however, we cannot use rating scales to ask them
%about constructs as abstract as social presence or how much they felt involved
%in the interaction.

%We have measured engagement by combining \emph{interaction} data with the
%results of the semi-structured interviews.  Several of the aforementioned coded
%actions can reflect engagement: \textit{explore, misuse, gesture, touch, show,}
%and \textit{talk}. Also, \textit{look} at the experimenter can be considered as
%engagement in the interaction: We assume that children look at the experimenter
%when they are surprised and seek for help.  This behavior reflects that they
%want to make sense of the robot's behavior. Further, we can take into account
%how they refer to \emph{Ranger} and describe the robot (as well as their experience) in
%the interviews.  Specifically, we used the constructs \textit{ascribe intention,
%ascribe cognitive abilities, ascribe emotional state}, and \textit{ascribe moral
%standing} (Table~\ref{tab:domino-questions}) to assess how far they engaged with
%the robot.
%
Because the tendency to anthropomorphize manifests itself both in terms of
perception and behavior, we propose to build a compound index that brings both
children's perception of the robot (post-measurement) and their behavior toward
it (in-the-moment measurement) together. We build the index by attributing
points for each anthropomorphic \emph{perception} of the robot and for specific
kinds of human-like \emph{behavior} toward the robot, using the following
grading scheme:

\vspace{0.5em}
\textbf{Perception}

\begin{itemize}
    \item Ascription of \textbf{mental states / feelings}: \textit{2 points} for agreeing
            that \emph{Ranger} can be happy or sad; \textit{2 points} for attributing \emph{Ranger} with
        hunger or tiredness.

    \item Ascription of \textbf{cognitive abilities / intention}: each \textit{0.5
        points} for ascribing seeing and hearing ability; \textit{1 point} for agreeing
            that \emph{Ranger} can go out the door by itself; \textit{1 point} for disagreeing that
            \emph{Ranger} always obeys; \textit{1 point} for agreeing that \emph{Ranger} can do something
        silly.

    \item Ascription of \textbf{sociality / companionship}: \textit{1 point} for agreeing
        that \emph{Ranger} can be a friend.

    \item Ascription of \textbf{moral standing}: \textit{1 point} for disagreeing that
        \emph{Ranger} be left alone at home.

    \item Other \textbf{anthropomorphic statements}: \textit{1 point} for anthropomorphic
        reason for \emph{Ranger}'s misbehavior; \textit{2 points} for anthropomorphic reason
        for not leaving \emph{Ranger} alone (\eg \textit{``It would be sad''}).

\end{itemize}

\textbf{Behavior}

\begin{itemize}
    \item Use of \textbf{direct speech}: \textit{1 point} (not considering
        \textit{calling} the robot to come over).

    \item Use of \textbf{polite formulations}: \textit{1 point} (\eg
        \textit{``thank you \emph{Ranger}''} or \textit{``please \emph{Ranger} ...''}).

    \item Use of \textbf{social or pointing gestures}: \textit{1 point} (\eg
        waving at the robot).

\end{itemize}

The balance of the grading scheme is open to debate: for instance, we did not
consistently assign 1 point to each item, but assigned points between 0.5 and 2
points depending on our perception of how a given item reflect a higher level of
anthropomorphic perception of the robot (for instance, ascribing the ability to
see and hear was suggested by the design of the study, and we cannot assert it
really reflects the explicit projection of cognitive skills). This issue is
however mitigated by our use of this compound index as a \emph{relative} metric
(comparison between conditions) and not an absolute value.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Main Findings}

This section present our main findings, interleaving the analysis of perceptions
(interviews) with behavioral data (action annotations).

The analysis of interviews provides us with insights on the recognition of the
different misbehaviors of the robot by the children (manipulation check,
section~\ref{reco}), as well as a picture of the higher cognitive skills that
they project onto the robot (section~\ref{higher_cognition}).

On the other hand, the amount of actions performed in interaction with the robot
gives an estimate of the actual engagement of children
(section~\ref{engagement}).

Finally, analyzing the interaction between perception and behaviors lead to 
two remarkable clusters of children, adopting very different attitudes toward the
robot (section~\ref{antidx}).

\subsection{Misbehavior Recognition}
\label{reco}

%\paragraph{Misbehavior Recognition}

As stated in the introduction, we had hypothesised that the \textit{disobey}
behavior is perceived as the robot intentionally not doing what it should do.
The \textit{mistake} behavior was intended to show that the robot can do a
mistake but is aware of it and able to repair its mistake, which should also
lead to the perception of intentionality and introspective skills.  Contrary, we expected that the
\textit{lost} condition is perceived as a malfunction or bug of the robot.  In
the second interview, after the robot had misbehaved, we asked children whether
the robot always did what they wanted it to do. Most children disagreed and said
they noticed something strange.
%However, there were some children who gave a
%positive answer, suggesting that they found the robot always did what they
%wanted it to do. This was a surprise. Had they not noticed the robot's
%misbehavior? Why not? On one hand, we found that children sometimes gave
%contradictory replies when asked the same question twice. This is difficult to
%interpret. On the other hand, children may have a general tendency to please
%adults \cite{leite_long-term_2013}, and it could be the case that some were too
%shy to tell us that the robot did something strange.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.8\linewidth]{domino-why-misbehavior.pdf}   
    \caption[Why Did the Robot Misbehave?]{\small Multiple answers were possible
    to the question why the robot did not come over, and we received 37 answers.}

    \label{fig:domino-why-misbehavior}
\end{figure}	

When asked why they thought the robot had not always come over to them, 4 of the
children did not reply. The remaining ones gave a variety of reasons
(Figure~\ref{fig:domino-why-misbehavior}). The most common answer (9 of 37
replies) was that the robot is somehow \textit{unpredictable} in what it is
doing and that it could go \textit{``no matter where''}\footnote{We translated
children's answers from French to English. For some expressions the meaning
and connotation of an expression may not be the same. We understand
\textit{``partir dans tous les sens''} as ``to go off in all possible
directions'' and hence interpret this reflects viewing the robot as being
unpredictable.} because \textit{``with robots you have these kind of problems,
they do no matter what''}. 8 replies related to \textit{technical problems}
(including \textit{broken parts}), suggesting that children perceived the
misbehavior as unintended by the robot. Two of the children who had interacted
with the disobeying robot said \emph{Ranger} was \textit{angry}, which none of
the children in other conditions replied. 13 out of 26 children appeared to
ascribe intentionality precursors to \emph{Ranger} explaining that it
\textit{did not want to continue} carrying domino tiles or that it \textit{``did
something silly''}\footnote{We understood \textit{``faire une bêtise''} as ``to
do a silly thing'' in the sense of making a mistake.}.

%	\textit{``the supportive behavior ``Play Bad Move'' was not completely
%	understood as a deliberative action of the robot, but rather as a
%	mistake''}. 	

%In our case, it is not easy to make a clear statement about how each of the
%manipulations was perceived by the children.  Similar to how people reacted to
%the cheating robot in the study of \cite{short_no_2010}, most children showed
%surprise, were amused, sometimes confused, or occasionally slightly angry (\eg
%two boys tended to shout to the robot after it had disobeyed). The
%\textit{disobeying} robot seemed to evoke the strongest reactions, partly with a
%negative implication: later three of the children in this condition stated they
%would not accept \emph{Ranger} as a friend \textit{because it did not always come over
%when they asked it to come over}. \cite{short_no_2010} described a similar
%implication of the robot cheating behavior: participants made unfavorable
%character attributions to the cheating robot, so the robot's actions affected
%perceptions of the robot as ``fair'' and ``honest''.


%	\cite{short_no_2010} found that participants often had an emotional reaction
%	to the robot's behavior and made unfavorable character attributions to the
%	cheating robot. The robot's actions affected perceptions of the robot as
%	``fair'' and ``honest''. Qualitatively, the authors found that participants'
%	reactions in the verbal cheat case tended more towards confusion, while
%	their reactions to the action cheat were more exaggerated, showing surprise,
%	amusement, and occasionally anger.  	

%	\cite{short_no_2010} found that participants who saw the action cheat
%	mentioned cheating, while the participants who saw the verbal cheat
%	frequently described it as a mistake or malfunction, while only sometimes
%	calling it cheating.

\subsection{Attribution of Higher Cognitive Skills}
\label{higher_cognition}

\paragraph{Intentionality}

One of the central points of this study was to investigate to what degree
children attribute intention and cognitive abilities to the robot.  In the first
interview after children had interacted with the correctly behaving robot we
asked three questions to assess how far they ascribe \textbf{intention} to it
(see questionnaire items in Table~\ref{tab:domino-questions}). One of these
questions was whether they believed \emph{Ranger} could go out the door by
itself. A majority of 16 children answered negatively, which suggests that
they initially do not ascribe intention to the robot. The two other questions
were whether Ranger would always obey and whether \emph{Ranger} could do a silly
thing (Figure~\ref{fig:domino-intention}). These two questions were asked again
later after children had interacted with the unexpectedly behaving robot.

%	With these recurring questions we wanted to see whether children had changed
%	their mind in terms of ascribing intention to \emph{Ranger} (and whether the
%	unexpected robot behavior had caused this effect). This comparison turned
%	out to be difficult, however.  	

\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\linewidth]{domino-intention.pdf}
    \caption{\small \textbf{Attribution of intention to \emph{Ranger}.} Children were
        asked these questions at both interviews. Concerning question (a), there
        are no remarkable differences in children's responses given in the
        \textit{first} and \textit{second} interview.  Children tend to think
        \emph{Ranger} does always obey to them, even after it misbehaved. There is
        however a small difference in the responses to question (b).  After the
        robot misbehaved, 8 children think the robot could do something silly whereas
        first, only 3 children answered like this.}
    
    \label{fig:domino-intention}

\end{figure}


In the first interview, 12 out of the 15 children who provided an answer
believed that \emph{Ranger} does always obey to them. Asked whether the robot
could do something silly, a large majority of 21 children out of 24 replied
negatively: it appears that after children the first round of interaction (with
the \textbf{correctly behaving robot}) the children does \textbf{not} generally
\textbf{ascribe intention} to the robot.

After interacting with the misbehaving robot (second interview), most of the
children still believed that \emph{Ranger} always obeys to them.  However, 8
children (previously~3) think that \emph{Ranger} could do something silly. One
child in the \textit{disobey} condition had changed his answer, and two in each
the \textit{mistake} and \textit{lost} conditions: even with an
\textbf{unexpectedly behaving robot} children do \textbf{not necessarily ascribe
intention} to the robot.  It seems that some children did not interpret the
misbehavior of the robot as intentional but more like a technical problem or
mistake. For instance, even after the robot misbehaved by \textit{disobeying},
the majority of the children in this condition was still convinced that the
robot could not do a silly thing.  It is however interesting to note that
children tend to ascribe cognitive abilities to the robot, like the ability to
see and hear but not intention. We interpret this as children perceiving the
robot as being able to process sensory information but not being able to make
decisions on its own.

%\paragraph{Emotions and Companionship}
%
%We examined whether children attribute \textbf{feelings} to the robot by asking
%them (once at the end of the experiment) if they thought that \emph{Ranger} can feel
%happy or sad sometimes. The majority of
%children (21 of 26) gave a positive answer. Only 2 children who had interacted
%with the \textit{disobeying} robot did not believe that \emph{Ranger} has feelings and
%another 3 children (2 \textit{disobey} and 1 \textit{lost}) did not reply at
%all. Overall, data suggests that \textbf{children attribute emotional states}
%to the robot. Asked for more details, several children answered that it is
%through its colours and sounds that the robot shows a feeling. Most children said
%that they could make the robot feel happy by playing with it and putting a
%domino tile inside the box. This may also be a reflection of their own feelings,
%projected on the robot. About half of the children (14 of 26) agreed that \emph{Ranger}
%can be their friend. We did not ask about what being a friend means to them but
%as children generally liked playing with the robot, this may be linked to each
%other. We can note that children \textbf{ascribe feelings to the robot and
%partly accept that it can be a ``friend''}.

\vspace{1em}
\paragraph{Moral standing}

Inspired from the questionnaire used by \cite{kahn_jr._robotic_2006}, we asked
children if it would be alright to leave \emph{Ranger} alone at home (\eg during two
weeks when they go on a vacation) (Figure~\ref{fig:domino-leave-alone}). 
20 out of 26 children responded negatively. Asked why, children gave a
variety of answers that we classified into 6 categories. With 5 replies, the
most common answer was that the robot ``could do something silly''. Some other
children simply answered they would like to take it with them. Others were
afraid that the \emph{Ranger} ``would not find its way'' or ``may be taken away by
someone''. 2 children believed \emph{Ranger} is sad when left alone and 1 child
responded the robot would try to escape. Interestingly, and while we intuitively
expected many children to fear that the robot would be sad if left alone, only 2
expressed a moral position, while most of the others actually expressed several
forms of distrust towards the robot. This shows that things must
be put into perspective and even young children do not automatically consider a
so-called social robot as an actual social agent that deserves care.

\begin{figure}[!h]
    \centering 
    \includegraphics[width=1.0\linewidth]{domino-leave-why.pdf}
    \caption{\small Attributions of moral
        standing: we asked children whether it was alright to leave \emph{Ranger}
        alone at home if they go on a 2-week vacation. Multiple answers
        (open-ended) were allowed when asked to justify their answer.}

    \label{fig:domino-leave-alone} 
\end{figure}

\subsection{Engagement}
\label{engagement}

%The huge proportion of \textit{explore} actions (52~\% of all coded actions)
%already suggests that children were generally engaged in the interaction, and
%most of the time carefully observed what the robot did. When considering the
%actions \textit{explore, gesture, look, misuse, show, talk}, and \textit{touch}
%as \textbf{engagement actions}, 1699 of the 2354 actions reflected engagement
%(72~\%). This indicates that overall children were very engaged in the
%interaction with the robot.
%
%
%Furthermore, data suggests that the robot in the
%\textit{mistake} and \textit{lost} condition was more engaging for children
%(each 75~\% of the actions reflected engagement) than the robot in the
%\textit{disobey} condition (66~\% reflected engagement). The statistical
%analysis supports this: An ANOVA indicates that there was a significant effect
%of robot behavior on the actions \textit{explore} (F(2,23)=11.31, p<.001) and
%\textit{look} (F(2,23)=4.6, p=.021). Post-hoc comparisons using the Tukey's test
%indicate that the mean score for \textit{explore} in the \textit{disobey}
%condition is significantly different from the score in the \textit{mistake} and
%\textit{lost} condition. This suggests that children explored the disobeying
%robot less\footnote{It is surprising that the disobeying robot was explored
%less. One may expect that the disobeying robot might better attract
%children's attention because it faces the searcher child and uses fairly
%strong audio and light cues as compared to the other behaviors.}. 

We found a significant difference between the average of engagement actions
(Figure~\ref{fig:domino-time-active}) carried out during the first 7 runs
(correct robot behavior) and during the second 7 runs, when the robot behaved
unexpectedly (F(1,36)=5.1, p=.03). In all three conditions, children carried out
more engagement actions with the unexpectedly behaving robot.  Importantly, no
interaction effect was found between the two phases of interaction (expected /
unexpected) and condition (F(2,36)=1.2, p=.31): the robot's failure mode does
not seem to impact the level of engagement.

In general, this finding \textbf{supports our first hypothesis}: children show
more engagement toward a robot that behaves unexpectedly from time to time
compared to a robot that always behaves correctly.

It must be noted that the novelty of the robot plays an important role. Our
findings do not directly address the issues of long-term usage and are
effectively focused on short-term \textit{engagement}, which is a pre-requisite
for long-term usage.

\subsection{Anthropomorphic Projections}
\label{antidx}

The compound index of anthropomorphism, presented at section~\ref{antidx},
expresses to what extent children engaged with \emph{Ranger} in a human-like
way, both in terms of their behavior toward the robot and their perception of
the robot (the findings presented hereafter are at pair (group) level).

%To obtain the anthropomorphism index for a pair, we first calculated the index
%per child and then took the average of the two children in one group.  The group
%indexes varied between 3.25 and 10.75 points with an average of 7.5 points
%(SD~=~2.5), which is 47~\% of the maximum possible index of 16 points.
%Intra-group variations were interesting: In 7 of the 13 groups, the
%anthropomorphism indexes for both children were similar (difference less than
%1.5 points). This agreement among children happened for both higher and lower
%indexes. In 6 of the 13 groups, the anthropomorphism indexes varied in more than
%2 points, which means that one of the children anthropomorphized the robot more
%than the other one.

On average, \emph{Ranger} was moderately anthropomorphized by the children. 8 of
the 13 groups had an index of 8 or higher, evenly spread over the three
conditions (table~\ref{tab:domino-anth-score}).  However, the mean index of
anthropomorphism in the three conditions varied, with the \textit{mistake} and
\textit{lost} condition leading to a higher index than the \textit{disobey}
condition. This finding suggests that the disobeying robot was \emph{less}
anthropomorphized than the other two robot behaviors, which speaks
\textbf{against our second hypothesis}. We had expected that the disobeying
behavior is perceived as an intentional action which we assumed would lead to
increased anthropomorphism. This was not the case. The slight difference between
the \textit{lost} and \textit{mistake} robot was also expected in the opposite
direction and the \textit{lost} robot was overall the one eliciting the highest
level of anthropomorphism (the robot's ``helplessness'' may have lead to this). This is
also reflected in children's behavior: with the lost robot, children looked more
often at the experimenter than in the other condition, which suggests that they
could not fully make sense of the robot's behavior, and the fact of not being
able to understand (and hence predict) a robot's behavior is likely to increase
anthropomorphism.\footnote{One of the cognitive / psychological explanations for
anthropomorphism is that people want to make sense of something they do not
understand and then tend to anthropomorphize this something (human traits
are a good source of making attributions because this is what people
understand best -- themselves and other humans). For more details the reader
may refer to~\cite{epley_seeing_2007}.}

\begin{table}[ht!] \centering \footnotesize \begin{tabular}{lccc} \toprule & M
& SD & groups with index $> 8$ \\ \midrule

        \textit{lost} & \textbf{8.31} & 0.59 & 3 of 4 \\ \textit{disobey} & 6.5
        & 3.68 & 2 of 5 \\ \textit{mistake} & 7.94 & 1.74 & 3 of 4 \\
        \bottomrule \end{tabular} \caption{\small \textbf{Anthropomorphism
        index.} The maximum possible index was 16. The \textit{lost} robot
        elicits the highest index, which suggests that it is anthropomorphized
        more. Contrary to our hypothesis, data suggests that the
        \textit{disobeying} robot is anthropomorphized less but the
        \textit{lost} robot more.}

    \label{tab:domino-anth-score}       % Give a unique label
\end{table}	

We hypothesised that children who interact a lot and are probably more engaged
with the robot also perceive the robot as more human-like. Data suggests the
opposite, however. As shown in Figure~\ref{fig:domino-anthropo-interaction}, 
%(we even found a significant \textit{negative} correlation between the count of
%engagement actions (per group) and the qualitative anthropomorphism index --
%r(11)=-0.56, p=.05 -- but the sample size is too small to report it).  (b=-.05,
%t(11)=-2.22, p=.048).  The overall model with the count of engagement actions
%(per group) predicts a significant proportion of the qualitative
%anthropomorphism index (adjusted R$^2$=.25, F(1,11)=4.9, p=.05). This means
%that 
\textbf{the more a group showed engagement in the interaction, the less they
anthropomorphized the robot}. This is a key result, which was against our
initial assumption. A possible interpretation is that children who interact more
with the robot understand better how it works, they are more familiar with it,
and as such the robot appears less ``mystical'' to them, and they hence do not
need to anthropomorphize it. On the contrary, the cluster of groups that do not
interact much but anthropomorphize the robot more, is quite homogeneous, and may
reflect a certain fear of interacting with a robot that would look to them too
human-like.
%The negative correlation between the number of engagement actions and the
%anthropomorphism index suggests that children who interact more with the robot
%tend to anthropomorphize it less. This implies that anthropomorphism could fade
%out after some time (or rather after some interaction).
This raises the question how far anthropomorphism (as a special kind of social
engagement) really helps in sustaining interaction. This is a critical point
because most of the short-term investigations suggest that anthropomorphic
design and human social cues emitted by a robot foster engagement and
acceptance. What if this is not true for continued interaction, and thus for the
long-term? We need to remain modest here: while we found a significant
\emph{negative} correlation between engagement and anthropomorphism in the data
pictured on Figure~\ref{fig:domino-anthropo-interaction} (r(11)=-0.56, p=.05),
we have to be careful about our interpretation, due to the small sample size (13
pairs), and we suggest to investigate the aspect further in future research.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\columnwidth]{domino-correlation.pdf}   

    \caption{\small \textbf{Anthropomorphic perception of the robot versus
        engagement actions per pairs.} A scatter plot of the count of engagement
        actions and the \textit{anthropomorphic
        perception} (score per group) evidence one cluster of
        high-anthropomorphizers/low-interactors and a another group of pairs who
        interact more with the robot and anthropomorphize it less. The score for
        the anthropomorphic perception (\textit{y-axis}) does not take into
        account the behavioral aspect of the anthropomorphism index, as this is
        part of the interaction (\textit{x-axis}).}

    \label{fig:domino-anthropo-interaction}
\end{figure}	

%Our data on the anthropomorphism index also suggest \textbf{qualitative gender
%differences} in children's tendency to anthropomorphize \emph{Ranger}. Boys (M=8.2,
%SD=3.0) obtained a higher mean index of anthropomorphism than girls (M=6.4,
%SD=2.4). (Interestingly, as it was mentioned before, boys interacted slightly
%more with the robot than girls; though not significantly. This is
%counter-intuitive concerning the negative correlation between amount of
%interaction with the robot and anthropomorphism tendency.) It would be
%interesting to investigate in more detail whether boys are more prone to
%anthropomophize a robot than girls.\footnote{Findings presented in
%\cite{schermerhorn_robot_2008} suggested similar gender differences. In their
%study, males tended to think of the robot as more human-like and accordingly
%showed more ``social facilitation'' than females, who perceived the robot as
%more machine-like.} 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions and Future Directions}


As hypothesised, we found that in a playful scenario where 4-5 year old children
play domino together with a robot, the robot seems to be more engaging when it
shows some misbehavior compared to when it always behaves as expected
(notwithstanding the impact of a novelty effect).

Regarding the design of our three conditions (\emph{lost}, \emph{disobey},
\emph{mistake}), we cannot conclusively affirm whether children perceived the
unexpected robot behavior as a malfunction (something that happens to a machine)
or as being intended and based on a motivation (something related to a social
entity). Children stated both, when asked why the robot had misbehaved.  Some
referred to \textit{``a technical problem''} while others said the robot
\textit{``is tired''} or it \textit{``doesn't want to carry domino tiles any
more but rather go on a tour outside''}. While our manipulations were not as
clearly perceived as we expected for the age range of the subjects, we still
believe these three conditions (mechanical malfunction -- the \emph{lost}
condition, vs. explicit intentionality -- the \emph{disobey} condition, vs.
implicit intentionality -- the \emph{mistake} condition) are relevant and we
suggest to replicate a similar study with slightly older children.


%It also appears
%From what we
%have seen in the Domino Study, we have a rough estimate of how children react
%and relate to a robot that behaves unexpectedly from time to time. They are
%mostly surprised, laugh at the robot, and they tend to be more engaged and
%playful. However, they are also confused and cannot really make sense of the
%robot's strange behavior. We also cannot conclusively tell apart whether children perceived
%the unexpected robot behavior entirely as a malfunction (something that happens
%to a machine) or as being intended and based on a motivation (something related
%to a social entity). Children stated both, when asked why the robot had
%misbehaved. Some referred to \textit{``a technical problem''} while others said
%the robot \textit{``is tired''} or it \textit{``doesn't want to carry domino
%tiles any more but rather go on a tour outside''}. Maybe our manipulations were
%not as clearly designed as we expected. There is always some freedom in how
%things are interpreted -- especially with young children.  Certainly more work
%needs to be done to investigate which robot behavior is most beneficial for
%young children and can promote their engagement and motivation to interact with
%Ranger over extended periods of time.  


%	Whereas a cheating opponent is acting out of a desire to win the game, a
%	malfunction, on the other hand, is entirely accidental, and could be the
%	fault of physical design or faulty programming, and can even occur entirely
%	without involvement on the part of the robot. \textit{``A malfunction is
%	something that happens to a machine, while a social entity that can cheat
%	has motivations and desires.'' Short et al.}


%\subsection{Limitations}
%
%This study and the results have several limitations.  First, we did not have a
%real control group in which the robot always behaved correctly. Instead, we took
%the first interaction phase as a reference for how children interact with the
%correctly behaving robot.  Also, the sample size of 13 groups was small. There
%were  variations in the data due to the individual differences of children. More
%data could have allowed for a better comparison between the conditions.
%
%With the manipulation of the robot behavior we were able to surprise children.
%However, it is questionable how often the same type of behavior manipulation
%leads to surprise. Moreover, our experiment was a short-term interaction study
%while we try to make statements about how to sustain long-term engagement. This
%is critical but not unusual. Long-term HRI studies with young children are
%extremely rare as they are difficult to set up as well as time and resource
%consuming \cite{leite_long-term_2013}. Nevertheless, we could have probably
%improved our study by setting up several short interaction sessions spreading
%over several weeks. At the end of each session we could have asked whether
%children want to play again with the robot. Such a study could have helped to
%investigate the long-term interaction with the robot and the impact of the
%behavioral variances.
%
%\subsection{Lessons Learned}
%
%One of the lessons learned is that it is difficult to set up a controlled lab
%study with young children. Children are not like adults who patiently
%participate in a 45-minutes experiment and then get some reward in the end. On
%one hand, an experiment with children should not be boring for them, but on the
%other hand, you would like to seriously collect some data. A lot of the
%challenges we experienced are also described in \cite{ros_child-robot_2011}. One
%of the most difficult parts turned out to be the interviews with the children.
%We need to be careful to not over interpret some of their answers. Some children
%seem to not have a clear opinion and partly contradict themselves. These answers
%are not easy to interpret. An interview script including the questions need to
%be designed very carefully, and should definitely be tested beforehand with the
%respective age group.
%
%Overall, it appears that when trying to study something in more detail, such as
%the manipulation of robot behavior, 4-5 year old children may be too young. But
%when trying to evaluate a more general approach, the design of a prototype, or
%an interaction scenario, children are a very good choice. They say things as
%they are and react very naturally, when compared to adults, who may reply more
%socially desired. 
%
%
%\paragraph{Summary}

%In this study, we investigated the effect of unexpected robot behavior on
%children's engagement in interacting with \emph{Ranger} and on their perception of the
%robot.  Our first hypothesis finds support: children show more engagement toward
%a robot that behaves unexpectedly from time to time. Further, different types of
%unexpected behavior may have a different effect, and therefore the behavior
%manipulation needs to be designed with care.

Still, we did not find support for our second hypothesis which stated that
children perceive a robot showing intention or cognitive abilities as more
human-like than a robot that appears to have a system error. While this may be
due to the study setup and the fact that children did not interpret the robot
misbehavior in the conceived way, our findings seem to suggest the contrary to
our hypothesis. A robot that appeared to do a \textit{mistake} or to be
\textit{lost} was more anthropomorphized than a robot that \textit{disobeyed}.


Another outcome of this study is the initial application of an compound index of
anthropomorphism to assess children's anthropomorphic projection onto robots.
This index considers both behavioral and phenomenological aspects, and it
suggests, in our experiment, that children tend to conditionally
anthropomorphize the robot. Higher indexes of anthropomorphism were found in the
\textit{lost} and \textit{mistake} condition which was against our hypothesis.

Interestingly, data suggests that anthropomorphic perception does not
automatically elicit  engagement, on the contrary. It appears that groups who
interacted more with the robot perceived it as less human-like. This raises an
important question for the human-robot interaction community: to what extent do
anthropomorphic perceptions impact the interaction experience? Our findings here
go against the intuition.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgements}

We would like to thank all the families who participated to the study.
This research was supported by the Swiss National Science Foundation through the
National Centre of Competence in Research Robotics.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{IEEEtran}
\bibliography{domino}


\end{document}
